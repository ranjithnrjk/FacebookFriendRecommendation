{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ngfVeOrX7If"
   },
   "source": [
    "<p style=\"font-size:32px;text-align:center\"> <b>Social network Graph Link Prediction - Facebook Challenge</b> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BIdTcywoX7Ih"
   },
   "source": [
    "### Problem statement: \n",
    "Given a directed social graph, have to predict missing links to recommend users (Link Prediction in graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EKXSOWj3X7Ii"
   },
   "source": [
    "### Data Overview\n",
    "Taken data from facebook's recruting challenge on kaggle https://www.kaggle.com/c/FacebookRecruiting  \n",
    "data contains two columns source and destination eac edge in graph \n",
    "    - Data columns (total 2 columns):  \n",
    "    - source_node         int64  \n",
    "    - destination_node    int64  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "frIBf5F2X7Ij"
   },
   "source": [
    "### Mapping the problem into supervised learning problem:\n",
    "- Generated training samples of good and bad links from given directed graph and for each link got some features like no of followers, is he followed back, page rank, katz score, adar index, some svd fetures of adj matrix, some weight features etc. and trained ml model based on these features to predict link. \n",
    "- Some reference papers and videos :  \n",
    "    - https://www.cs.cornell.edu/home/kleinber/link-pred.pdf\n",
    "    - https://www3.nd.edu/~dial/publications/lichtenwalter2010new.pdf\n",
    "    - https://kaggle2.blob.core.windows.net/forum-message-attachments/2594/supervised_link_prediction.pdf\n",
    "    - https://www.youtube.com/watch?v=2M77Hgy17cg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zej3Dqi7X7Ik"
   },
   "source": [
    "### Business objectives and constraints:  \n",
    "- No low-latency requirement.\n",
    "- Probability of prediction is useful to recommend ighest probability links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fSW6zbsHX7Il"
   },
   "source": [
    "### Performance metric for supervised learning:  \n",
    "- Both precision and recall is important so F1 score is good choice\n",
    "- Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jGe4BKx9X7Im"
   },
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "# please do go through this python notebook: \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import csv\n",
    "import pandas as pd#pandas to create small dataframes \n",
    "import datetime #Convert to unix time\n",
    "import time #Convert to unix time\n",
    "# if numpy is not installed already : pip3 install numpy\n",
    "import numpy as np#Do aritmetic operations on arrays\n",
    "# matplotlib: used to plot graphs\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns#Plots\n",
    "from matplotlib import rcParams#Size of plots  \n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans#Clustering\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "# to install xgboost: pip3 install xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "import networkx as nx\n",
    "import pdb\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OOi4aONAX7Iv",
    "outputId": "b413d19f-8322-43df-c9da-d88a60d5fe1c"
   },
   "outputs": [],
   "source": [
    "#reading graph\n",
    "if not os.path.isfile('data/after_eda/train_woheader.csv'):\n",
    "    traincsv = pd.read_csv('data/train.csv')\n",
    "    print(traincsv[traincsv.isna().any(1)])\n",
    "    print(traincsv.info())\n",
    "    print(\"Number of diplicate entries: \",sum(traincsv.duplicated()))\n",
    "    traincsv.to_csv('data/after_eda/train_woheader.csv',header=False,index=False)\n",
    "    print(\"saved the graph into file\")\n",
    "else:\n",
    "    g=nx.read_edgelist('data/after_eda/train_woheader.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)\n",
    "    print(nx.info(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ba1XVmouX7I2"
   },
   "source": [
    "> Displaying a sub graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rvhGErEXX7I3",
    "outputId": "3211434c-3826-4d98-af7e-949329c2906a"
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('train_woheader_sample.csv'):\n",
    "    pd.read_csv('data/train.csv', nrows=50).to_csv('train_woheader_sample.csv',header=False,index=False)\n",
    "    \n",
    "subgraph=nx.read_edgelist('train_woheader_sample.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)\n",
    "# https://stackoverflow.com/questions/9402255/drawing-a-huge-graph-with-networkx-and-matplotlib\n",
    "\n",
    "pos=nx.spring_layout(subgraph)\n",
    "nx.draw(subgraph,pos,node_color='#A0CBE2',edge_color='#00bb5e',width=1,edge_cmap=plt.cm.Blues,with_labels=True)\n",
    "plt.savefig(\"graph_sample.pdf\")\n",
    "print(nx.info(subgraph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QirDnZ-FX7I8"
   },
   "source": [
    "# 1. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gdlTIj97X7I9",
    "outputId": "2e956d78-2d25-45be-e390-fa64bd98225c"
   },
   "outputs": [],
   "source": [
    "# No of Unique persons \n",
    "print(\"The number of unique persons\",len(g.nodes()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BdvJPYMHX7JC"
   },
   "source": [
    "## 1.1 No of followers for each person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4fFEbqiSX7JD",
    "outputId": "d4aab961-ab7b-44c8-a6b0-de6c9ed04691"
   },
   "outputs": [],
   "source": [
    "indegree_dist = list(dict(g.in_degree()).values())\n",
    "indegree_dist.sort()\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(indegree_dist)\n",
    "plt.xlabel('Index No')\n",
    "plt.ylabel('No Of Followers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CZPczewbX7JL",
    "outputId": "ef79e2c1-ccc2-4d11-915d-01bee576f0a2"
   },
   "outputs": [],
   "source": [
    "indegree_dist = list(dict(g.in_degree()).values())\n",
    "indegree_dist.sort()\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(indegree_dist[0:1500000])\n",
    "plt.xlabel('Index No')\n",
    "plt.ylabel('No Of Followers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wqf9qkr_X7JS",
    "outputId": "6e880aa0-6fe3-4d22-e813-85141dab0678"
   },
   "outputs": [],
   "source": [
    "plt.boxplot(indegree_dist)\n",
    "plt.ylabel('No Of Followers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5q9wSyvGX7JY",
    "outputId": "54a2deaa-d1f0-487d-d6ab-84d1645be6ed"
   },
   "outputs": [],
   "source": [
    "### 90-100 percentile\n",
    "for i in range(0,11):\n",
    "    print(90+i,'percentile value is',np.percentile(indegree_dist,90+i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9HvreJYlX7Jf"
   },
   "source": [
    "99% of data having followers of 40 only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mt8DA-MmX7Jg",
    "outputId": "0ac13b00-ca01-4baf-cb93-fc50efc2959b"
   },
   "outputs": [],
   "source": [
    "### 99-100 percentile\n",
    "for i in range(10,110,10):\n",
    "    print(99+(i/100),'percentile value is',np.percentile(indegree_dist,99+(i/100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hZQed_RqX7Jk",
    "outputId": "bb5921e4-c9f5-48b8-c0d7-963d86cc9f99"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set_style('ticks')\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(11.7, 8.27)\n",
    "sns.distplot(indegree_dist, color='#16A085')\n",
    "plt.xlabel('PDF of Indegree')\n",
    "sns.despine()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F_rfNRYCX7Jx"
   },
   "source": [
    "## 1.2 No of people each person is following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L-2plpMuX7Jy",
    "outputId": "1355b363-1079-44e5-d062-ee352036d126"
   },
   "outputs": [],
   "source": [
    "outdegree_dist = list(dict(g.out_degree()).values())\n",
    "outdegree_dist.sort()\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(outdegree_dist)\n",
    "plt.xlabel('Index No')\n",
    "plt.ylabel('No Of people each person is following')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aNaQeE5cX7J2",
    "outputId": "c59a155f-c894-4600-9daf-35a45f7c8d4d"
   },
   "outputs": [],
   "source": [
    "indegree_dist = list(dict(g.in_degree()).values())\n",
    "indegree_dist.sort()\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(outdegree_dist[0:1500000])\n",
    "plt.xlabel('Index No')\n",
    "plt.ylabel('No Of people each person is following')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HVYdHvLAX7J7",
    "outputId": "da8978d6-76fe-400c-ff7d-ff60d2303efb"
   },
   "outputs": [],
   "source": [
    "plt.boxplot(indegree_dist)\n",
    "plt.ylabel('No Of people each person is following')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FVGmz09xX7KB",
    "outputId": "e2058803-7251-4836-df99-28075908ae99"
   },
   "outputs": [],
   "source": [
    "### 90-100 percentile\n",
    "for i in range(0,11):\n",
    "    print(90+i,'percentile value is',np.percentile(outdegree_dist,90+i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zcNoTvuzX7KF",
    "outputId": "b74b3bc9-146e-4106-b3df-af5f2a8938a0"
   },
   "outputs": [],
   "source": [
    "### 99-100 percentile\n",
    "for i in range(10,110,10):\n",
    "    print(99+(i/100),'percentile value is',np.percentile(outdegree_dist,99+(i/100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "27t51jOjX7KK",
    "outputId": "9655f989-f453-47db-be7b-732351ee3db3"
   },
   "outputs": [],
   "source": [
    "sns.set_style('ticks')\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(11.7, 8.27)\n",
    "sns.distplot(outdegree_dist, color='#16A085')\n",
    "plt.xlabel('PDF of Outdegree')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9LOGY_CyX7KT",
    "outputId": "eb5a2706-7829-4f99-c46d-84b0f7d03328"
   },
   "outputs": [],
   "source": [
    "print('No of persons those are not following anyone are' ,sum(np.array(outdegree_dist)==0),'and % is',\n",
    "                                sum(np.array(outdegree_dist)==0)*100/len(outdegree_dist) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hi30e3RmX7KX",
    "outputId": "f2feffac-585d-42ed-937f-5b61e1023040"
   },
   "outputs": [],
   "source": [
    "print('No of persons having zero followers are' ,sum(np.array(indegree_dist)==0),'and % is',\n",
    "                                sum(np.array(indegree_dist)==0)*100/len(indegree_dist) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rzX8vbh5X7Kc",
    "outputId": "0fa6651f-4449-478f-a480-e289b9706afd"
   },
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in g.nodes():\n",
    "    if len(list(g.predecessors(i)))==0 :\n",
    "        if len(list(g.successors(i)))==0:\n",
    "            count+=1\n",
    "print('No of persons those are not not following anyone and also not having any followers are',count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J7tiBqS3X7Kh"
   },
   "source": [
    "## 1.3 both followers + following "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MNu7k3-FX7Kj"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "dict_in = dict(g.in_degree())\n",
    "dict_out = dict(g.out_degree())\n",
    "d = Counter(dict_in) + Counter(dict_out)\n",
    "in_out_degree = np.array(list(d.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ARCqfS9TX7Kn",
    "outputId": "44fe1bc9-a591-4cff-89aa-e36c0f7165e5"
   },
   "outputs": [],
   "source": [
    "in_out_degree_sort = sorted(in_out_degree)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(in_out_degree_sort)\n",
    "plt.xlabel('Index No')\n",
    "plt.ylabel('No Of people each person is following + followers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jVlgsM8hX7Ku",
    "outputId": "28758bec-8303-4a93-f4a9-b637cb14efe0"
   },
   "outputs": [],
   "source": [
    "in_out_degree_sort = sorted(in_out_degree)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(in_out_degree_sort[0:1500000])\n",
    "plt.xlabel('Index No')\n",
    "plt.ylabel('No Of people each person is following + followers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4YpW20YEX7Kz",
    "outputId": "ba104e55-fae4-4a81-b2b6-887c804e6c6a"
   },
   "outputs": [],
   "source": [
    "### 90-100 percentile\n",
    "for i in range(0,11):\n",
    "    print(90+i,'percentile value is',np.percentile(in_out_degree_sort,90+i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LclmrhGbX7K3",
    "outputId": "43440486-b332-476b-a769-43e43e23600d"
   },
   "outputs": [],
   "source": [
    "### 99-100 percentile\n",
    "for i in range(10,110,10):\n",
    "    print(99+(i/100),'percentile value is',np.percentile(in_out_degree_sort,99+(i/100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XqErF9SRX7K8",
    "outputId": "11746c24-4d22-4466-f2bf-8dae306ee408"
   },
   "outputs": [],
   "source": [
    "print('Min of no of followers + following is',in_out_degree.min())\n",
    "print(np.sum(in_out_degree==in_out_degree.min()),' persons having minimum no of followers + following')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4rjy0p8-X7LA",
    "outputId": "e3d20325-27e8-44f3-f0ea-18aa395e687c"
   },
   "outputs": [],
   "source": [
    "print('Max of no of followers + following is',in_out_degree.max())\n",
    "print(np.sum(in_out_degree==in_out_degree.max()),' persons having maximum no of followers + following')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2vkQHuVgX7LE",
    "outputId": "c4bd961f-a5a9-45b7-d700-f8f368d6772d"
   },
   "outputs": [],
   "source": [
    "print('No of persons having followers + following less than 10 are',np.sum(in_out_degree<10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9YXunWI-X7LI",
    "outputId": "00c2e979-fcfc-412f-8a02-26bac9c912ff"
   },
   "outputs": [],
   "source": [
    "print('No of weakly connected components',len(list(nx.weakly_connected_components(g))))\n",
    "count=0\n",
    "for i in list(nx.weakly_connected_components(g)):\n",
    "    if len(i)==2:\n",
    "        count+=1\n",
    "print('weakly connected components wit 2 nodes',count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RiPVIlFUX7LQ"
   },
   "source": [
    "# 2. Posing a problem as classification problem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TpDCmJroX7LS"
   },
   "source": [
    "## 2.1 Generating some edges which are not present in graph for supervised learning  \n",
    "Generated Bad links from graph which are not in graph and whose shortest path is greater than 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3K2YQD6ZX7LT",
    "outputId": "03656e72-53e4-4239-8227-c0ffe9f535d1"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "###generating bad edges from given graph\n",
    "import random\n",
    "if not os.path.isfile('data/after_eda/missing_edges_final.p'):\n",
    "    #getting all set of edges\n",
    "    r = csv.reader(open('data/after_eda/train_woheader.csv','r'))\n",
    "    edges = dict()\n",
    "    for edge in r:\n",
    "        edges[(edge[0], edge[1])] = 1\n",
    "        \n",
    "        \n",
    "    missing_edges = set([])\n",
    "    while (len(missing_edges)<9437519):\n",
    "        a=random.randint(1, 1862220)\n",
    "        b=random.randint(1, 1862220)\n",
    "        tmp = edges.get((a,b),-1)\n",
    "        if tmp == -1 and a!=b:\n",
    "            try:\n",
    "                if nx.shortest_path_length(g,source=a,target=b) > 2: \n",
    "\n",
    "                    missing_edges.add((a,b))\n",
    "                else:\n",
    "                    continue  \n",
    "            except:  \n",
    "                    missing_edges.add((a,b))              \n",
    "        else:\n",
    "            continue\n",
    "    pickle.dump(missing_edges,open('data/after_eda/missing_edges_final.p','wb'))\n",
    "else:\n",
    "    missing_edges = pickle.load(open('data/after_eda/missing_edges_final.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vrjL2UAmX7LX",
    "outputId": "8596ad2d-6c45-4c14-e377-3c06850b661d"
   },
   "outputs": [],
   "source": [
    "len(missing_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LA2GGc3lX7Lb"
   },
   "source": [
    "## 2.2 Training and Test data split:  \n",
    "Removed edges from Graph and used as test data and after removing used that graph for creating features for Train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hmcOk-nkX7Lb",
    "outputId": "891d417c-069b-4236-e3ba-35b2bbfc252d"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "if (not os.path.isfile('data/after_eda/train_pos_after_eda.csv')) and (not os.path.isfile('data/after_eda/test_pos_after_eda.csv')):\n",
    "    #reading total data df\n",
    "    df_pos = pd.read_csv('data/train.csv')\n",
    "    df_neg = pd.DataFrame(list(missing_edges), columns=['source_node', 'destination_node'])\n",
    "    \n",
    "    print(\"Number of nodes in the graph with edges\", df_pos.shape[0])\n",
    "    print(\"Number of nodes in the graph without edges\", df_neg.shape[0])\n",
    "    \n",
    "    #Trian test split \n",
    "    #Spiltted data into 80-20 \n",
    "    #positive links and negative links seperatly because we need positive training data only for creating graph \n",
    "    #and for feature generation\n",
    "    X_train_pos, X_test_pos, y_train_pos, y_test_pos  = train_test_split(df_pos,np.ones(len(df_pos)),test_size=0.2, random_state=9)\n",
    "    X_train_neg, X_test_neg, y_train_neg, y_test_neg  = train_test_split(df_neg,np.zeros(len(df_neg)),test_size=0.2, random_state=9)\n",
    "    \n",
    "    print('='*60)\n",
    "    print(\"Number of nodes in the train data graph with edges\", X_train_pos.shape[0],\"=\",y_train_pos.shape[0])\n",
    "    print(\"Number of nodes in the train data graph without edges\", X_train_neg.shape[0],\"=\", y_train_neg.shape[0])\n",
    "    print('='*60)\n",
    "    print(\"Number of nodes in the test data graph with edges\", X_test_pos.shape[0],\"=\",y_test_pos.shape[0])\n",
    "    print(\"Number of nodes in the test data graph without edges\", X_test_neg.shape[0],\"=\",y_test_neg.shape[0])\n",
    "\n",
    "    #removing header and saving\n",
    "    X_train_pos.to_csv('data/after_eda/train_pos_after_eda.csv',header=False, index=False)\n",
    "    X_test_pos.to_csv('data/after_eda/test_pos_after_eda.csv',header=False, index=False)\n",
    "    X_train_neg.to_csv('data/after_eda/train_neg_after_eda.csv',header=False, index=False)\n",
    "    X_test_neg.to_csv('data/after_eda/test_neg_after_eda.csv',header=False, index=False)\n",
    "else:\n",
    "    #Graph from Traing data only \n",
    "    del missing_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wj9OwIX6X7Lh",
    "outputId": "8a11e605-e133-4b3d-c2d2-585021be9cdc"
   },
   "outputs": [],
   "source": [
    "if (os.path.isfile('data/after_eda/train_pos_after_eda.csv')) and (os.path.isfile('data/after_eda/test_pos_after_eda.csv')):        \n",
    "    train_graph=nx.read_edgelist('data/after_eda/train_pos_after_eda.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)\n",
    "    test_graph=nx.read_edgelist('data/after_eda/test_pos_after_eda.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)\n",
    "    print(nx.info(train_graph))\n",
    "    print(nx.info(test_graph))\n",
    "\n",
    "    # finding the unique nodes in the both train and test graphs\n",
    "    train_nodes_pos = set(train_graph.nodes())\n",
    "    test_nodes_pos = set(test_graph.nodes())\n",
    "\n",
    "    trY_teY = len(train_nodes_pos.intersection(test_nodes_pos))\n",
    "    trY_teN = len(train_nodes_pos - test_nodes_pos)\n",
    "    teY_trN = len(test_nodes_pos - train_nodes_pos)\n",
    "\n",
    "    print('no of people common in train and test -- ',trY_teY)\n",
    "    print('no of people present in train but not present in test -- ',trY_teN)\n",
    "\n",
    "    print('no of people present in test but not present in train -- ',teY_trN)\n",
    "    print(' % of people not there in Train but exist in Test in total Test data are {} %'.format(teY_trN/len(test_nodes_pos)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OhpyrSuiX7Ll"
   },
   "source": [
    "> we have a cold start problem here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "onultUqjX7Lm",
    "outputId": "795b2bac-18da-4540-9343-bb69f30a6f00"
   },
   "outputs": [],
   "source": [
    "#final train and test data sets\n",
    "if (not os.path.isfile('data/after_eda/train_after_eda.csv')) and \\\n",
    "(not os.path.isfile('data/after_eda/test_after_eda.csv')) and \\\n",
    "(not os.path.isfile('data/train_y.csv')) and \\\n",
    "(not os.path.isfile('data/test_y.csv')) and \\\n",
    "(os.path.isfile('data/after_eda/train_pos_after_eda.csv')) and \\\n",
    "(os.path.isfile('data/after_eda/test_pos_after_eda.csv')) and \\\n",
    "(os.path.isfile('data/after_eda/train_neg_after_eda.csv')) and \\\n",
    "(os.path.isfile('data/after_eda/test_neg_after_eda.csv')):\n",
    "    \n",
    "    X_train_pos = pd.read_csv('data/after_eda/train_pos_after_eda.csv', names=['source_node', 'destination_node'])\n",
    "    X_test_pos = pd.read_csv('data/after_eda/test_pos_after_eda.csv', names=['source_node', 'destination_node'])\n",
    "    X_train_neg = pd.read_csv('data/after_eda/train_neg_after_eda.csv', names=['source_node', 'destination_node'])\n",
    "    X_test_neg = pd.read_csv('data/after_eda/test_neg_after_eda.csv', names=['source_node', 'destination_node'])\n",
    "\n",
    "    print('='*60)\n",
    "    print(\"Number of nodes in the train data graph with edges\", X_train_pos.shape[0])\n",
    "    print(\"Number of nodes in the train data graph without edges\", X_train_neg.shape[0])\n",
    "    print('='*60)\n",
    "    print(\"Number of nodes in the test data graph with edges\", X_test_pos.shape[0])\n",
    "    print(\"Number of nodes in the test data graph without edges\", X_test_neg.shape[0])\n",
    "\n",
    "    X_train = X_train_pos.append(X_train_neg,ignore_index=True)\n",
    "    y_train = np.concatenate((y_train_pos,y_train_neg))\n",
    "    X_test = X_test_pos.append(X_test_neg,ignore_index=True)\n",
    "    y_test = np.concatenate((y_test_pos,y_test_neg)) \n",
    "    \n",
    "    X_train.to_csv('data/after_eda/train_after_eda.csv',header=False,index=False)\n",
    "    X_test.to_csv('data/after_eda/test_after_eda.csv',header=False,index=False)\n",
    "    pd.DataFrame(y_train.astype(int)).to_csv('data/train_y.csv',header=False,index=False)\n",
    "    pd.DataFrame(y_test.astype(int)).to_csv('data/test_y.csv',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DB_sXaqZX7Lt",
    "outputId": "6c5b1dcf-a7ff-420d-80fc-84a4fb6566fb"
   },
   "outputs": [],
   "source": [
    "print(\"Data points in train data\",X_train.shape)\n",
    "print(\"Data points in test data\",X_test.shape)\n",
    "print(\"Shape of traget variable in train\",y_train.shape)\n",
    "print(\"Shape of traget variable in test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ck2ytrgqX7Lz"
   },
   "outputs": [],
   "source": [
    "# computed and store the data for featurization\n",
    "# please check out FB_featurization.ipynb"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "FB_EDA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
